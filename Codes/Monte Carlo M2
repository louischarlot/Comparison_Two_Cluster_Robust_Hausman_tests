
#########################################################################################################
#########################################################################################################
# SETTINGS :         
#########################################################################################################
#########################################################################################################
rm(list=ls()) 		# Clear workspace

#install.packages("plm")
library (plm)

# Set working directory 
#setwd(dirname(rstudioapi::getActiveDocumentContext()$path))

# Load the 2 METHODS
source("Code_methode_1.R")

set.seed(1) 		    # Set seed for random number generator



#########################################################################################################
# CHOOSE CORRELATION OR NOT  :         
#########################################################################################################

CORRELATION <- "YES"
#CORRELATION <- "NO"




#########################################################################################################
#########################################################################################################
# SETTINGS FOR  DGP :         
#########################################################################################################
#########################################################################################################

number_clusters = 100        # Set the number of clusters
number_times = 10
n = number_clusters*number_times      # The sample size

delta = 5

# Number of w_it variables:
NUMBER_MEAN_VARIABLES <- 1

# Variance for Robust Wald statistic:
vcov_chosen <- vcovHC # CHECK BETTER !!!!!!!!!!!!







#########################################################################################################
#########################################################################################################
# MONTE-CARLO:         
#########################################################################################################
#########################################################################################################

num = 1000			# Number of Monte Carlo iterations


#Initialise !!!!!!!!!!!!!!!!
p_value_method_1_sum = 0
Hausman_stat_method_1_sum = 0



for (it in 1:num) {
  
  
  #########################################################################################################
  # DGP :         
  #########################################################################################################
  x_it = rnorm(n,1,1) 
  u_it = rnorm(n,0,1)  
  
  # Set the clusters i:
  cluster <- as.character(rep(1:number_clusters, times=1, each=n/number_clusters))
  cluster <- paste(cluster, "cluster", sep=".")
  
  # Set the times t:
  time <- as.character(rep(1:number_times, times=n/number_times, each=1))
  time <- paste(time, "time", sep=".")
  
  # Cluster names:
  cluster_names <- as.character(rep(1:number_clusters, times=1))
  cluster_names <- paste(cluster_names, "cluster", sep=".")
  
  # w_i is the meab of x_it in each cluster i: 
  data_to_determine_wi <- data.frame(x_it, cluster)
  data_to_determine_wi$w_i <- ave(data_to_determine_wi$x_it, data_to_determine_wi$cluster)
  w_i <- data_to_determine_wi$w_i
  
  
  
  
  if(CORRELATION == "NO"){
    ###########################################################################################################
    # Case 1 : NO correlation Corr(c_i,x_it) != 0 (Respect of RE.1.b) #########################################
    ###########################################################################################################
    # Same c_i (taken randomly) within a cluster:
    c_i = rep(rnorm(number_clusters,0,1), times=1, each=n/number_clusters)
    ###########################################################################################################
  }
  
  if(CORRELATION == "YES"){
    ###########################################################################################################
    # Case 2: correlation Corr(c_i,x_it) = 0 (Failure of RE.1.b)  #############################################
    ###########################################################################################################
    # There is correlation with the averages w_i (of x_it): 
    c_i = 0.01 * rep(rnorm(number_clusters,0,1), times=1, each=n/number_clusters)  +  0.99* w_i
    ###########################################################################################################
  }
  
  
  y_it = x_it * delta + c_i + u_it
  
  # Create the dataframe of observations:
  data0 <- data.frame(y_it = y_it, x_it = x_it, cluster = cluster, time = time)
  
  # We put the data into a panel-dataframe:
  data <- pdata.frame(data0, index = c("cluster","time"))
  
  # w_i is the mean of x_it in each cluster i:
  data$w_i <- ave(data$x_it, data$cluster)
  
  #########################################################################################################
  # Method 2:         
  #########################################################################################################
  
  
  ### b) bootstrap parametrisation 
  
  B = 399 #bootstrap coefficient
  
  # compute the estimated coefficients 
  reg <- y_it ~ x_it
  fe_0 <- plm(formula = reg, data = data, model = "within")
  beta_0_fe <- fe_0$coefficients
  re_0 <- plm(formula = reg , data = data, model = "random")
  beta_0_re <- re_0$coefficients
  
  # Initialization for the bootstrap
  k_fe = length(beta_0_fe)
  k_re = length(beta_0_re) 
  
  beta_fe_boot = matrix(0,B,k_fe)
  beta_re_boot = matrix(0,B,k_re)
  
  #2. Start boostrap code
  
  for (b in 1:B) {
    ### a) resample ? => PROPOSITION RACHEL
    
    # get a vector with all clusters
    c <- sort(unique(data$cluster))
    
    # group the data points per cluster
    clust.group <- function(c) {
      data[data$cluster==c,]             #### là ça ne fonctionne plus
    }
    
    clust.list <- lapply(c,clust.group)  #### et du coup là non plus
    
    # resample clusters with replacement
    c.sample <- sample(c, replace=T)  
    
    clust.sample <- clust.list[c.sample]
    
    clust.size <- number_times
    
    # combine the cluster list back to a single data matrix
    clust.bind <- function(c) {
      matrix(unlist(c),nrow=clust.size)
    }
    
    c.boot <- do.call(rbind,lapply(clust.sample,clust.bind)) # c.boot = the new data set (single bootstrap replicate)
    
    # Just to maintain columns name
    colnames(c.boot) <- names(data)
    
    ### Here the problem is that in the new sample dataset c.boot, some 'clusters' have been sampled more than once so we need to rename them otherwise plm does not work
    c.boot <- as.data.frame(c.boot)
    c.boot <- c.boot[order(c.boot$cluster),]
    c.boot$cluster <- rep(1:number_clusters, each=number_times) # no more duplicates !
    
    
    ### b) FE model   
    fe_mod <- plm(formula = reg, data = c.boot, model = "within")  
    beta_fe_boot[b,1:k_fe] <- fe_mod$coefficients
    
    ### c) RE model
    re_mod <- plm(formula = reg, data = c.boot, model = "random") 
    beta_re_boot[b,1:k_re] <- re_mod$coefficients
  }
  
  # re coefficients include time varying intercept while fe does not 
  # to have the same vector size, drop the intercept
  beta_0_re <- beta_0_re[2:k_re]
  beta_re_boot<-beta_re_boot[1:B,2:k_re]
  
  
  # 3. Create the haussman statistic 
  # we can use that V_hat(FE-RE) = V_hat_FE - V_hat_RE so we first calculate the two V_hat separately
  
  # Calculate V_hat_FE using the formula in Cameron and Miller (2015)
  betahat_bar_FE = 1/B*colSums(beta_fe_boot)
  beta_fe_boot_demeaned <- sweep(beta_fe_boot, 2, betahat_bar_FE, "-")
  
  list0_FE <- lapply(1:B, matrix, data=NA, nrow=k_fe, ncol=k_fe)
  for (i in 1:B){
    list0_FE[[i]] <- beta_fe_boot_demeaned[i,]%*%t(beta_fe_boot_demeaned[i,])
  }
  sum_mat_fe <- Reduce("+", list0_FE)
  
  varhat_betahat_FE <- 1/(B-1)*sum_mat_fe
  
  # Calculate V_hat_RE similarly 
  betahat_bar_RE = 1/B*colSums(beta_re_boot)
  beta_re_boot_demeaned <- sweep(beta_re_boot, 2, betahat_bar_RE, "-")
  
  list0_RE <- lapply(1:B, matrix, data=NA, nrow=k_re-1, ncol=k_re-1)
  for (i in 1:B){
    list0_RE[[i]] <- beta_re_boot_demeaned[i,]%*%t(beta_re_boot_demeaned[i,])
  }
  sum_mat_re <- Reduce("+", list0_RE)
  
  varhat_betahat_RE <- 1/(B-1)*sum_mat_re
  
  # The pairs cluster bootstrap variance is:
  V_hat_FE_RE = varhat_betahat_FE - varhat_betahat_RE
  
  # We calculate the difference between the estimated coefficients:
  diff_beta0_hat = beta_0_fe - beta_0_re
  
  ### d) generate the Hausman test statistic => follows a chi-square distribution with 3 degrees of freedom (because 3 coefs estimated)
  H = t(diff_beta0_hat)%*%(V_hat_FE_RE^(-1))%*%diff_beta0_hat
  H
  
  # 4. Test the statistic 
  # we want to compare the H statistic to a Chi-square distribution with 3 degrees of freedom
  #generate the p-value of H: 
  p_value_H <- pchisq(H, df=k_fe, lower.tail=FALSE)
  p_value_H

}




